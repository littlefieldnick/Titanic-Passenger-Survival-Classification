{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = pd.read_csv('./data/titanic_train.csv')\n",
    "    # Normalize Age and Fare Fields\n",
    "    train_dataset['Age'] = train_dataset['Age'].fillna(train_dataset['Age'].mean())\n",
    "    train_dataset['Age'] = (train_dataset['Age'] - train_dataset['Age'].mean())/train_dataset['Age'].std()\n",
    "    \n",
    "    train_dataset['Fare'] = (train_dataset['Fare'] - train_dataset['Fare'].mean())/train_dataset['Fare'].std()\n",
    "    train_dataset = train_dataset.drop(['PassengerId','Name','Ticket', 'Cabin'], axis=1)\n",
    "    train_dataset['Embarked'] = train_dataset['Embarked'].fillna('S')\n",
    "    train_dataset[\"Embarked\"] = train_dataset[\"Embarked\"].replace([\"S\",\"C\",\"Q\"], [1,2,3]).values\n",
    "    train_dataset[\"Sex\"] = train_dataset[\"Sex\"].replace([\"male\",\"female\"], [0,1]).values\n",
    "    train_set_x_orig = np.array(train_dataset.iloc[:, 1:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset['Survived']) # your train set labels\n",
    "\n",
    "    test_dataset = pd.read_csv('./data/titanic_test.csv')\n",
    "    # Normalize Age and Fare Fields\n",
    "    test_dataset['Age'] = test_dataset['Age'].fillna(test_dataset['Age'].mean())\n",
    "    test_dataset['Age'] = (test_dataset['Age'] - test_dataset['Age'].mean())/test_dataset['Age'].std()\n",
    "    test_dataset['Fare'] = (test_dataset['Fare'] - test_dataset['Fare'].mean())/test_dataset['Fare'].std()\n",
    "    test_dataset[\"Embarked\"] = test_dataset[\"Embarked\"].replace([\"S\",\"C\",\"Q\"], [1,2,3]).values\n",
    "    test_dataset[\"Sex\"] = test_dataset[\"Sex\"].replace([\"male\",\"female\"], [0,1]).values\n",
    "\n",
    "    test_dataset = test_dataset.drop(['Name','Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "    test_set_x_orig = np.array(test_dataset.iloc[:, 1:]) # your test set features\n",
    "    passenger_ids = np.array(test_dataset['PassengerId']) # your test set features\n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, passenger_ids\n",
    "\n",
    "# Read in datafile\n",
    "X, Y, X_test, passengerIds = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 1. ... 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    X = tf.placeholder(dtype = tf.float32, shape = [n_x, None])\n",
    "    Y = tf.placeholder(dtype = tf.float32, shape = [n_y, None])\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "# Build train and dev set\n",
    "train_sample_size = int(len(X) * 0.2)\n",
    "X_train = X[:len(X) - train_sample_size].T\n",
    "X_dev = X[len(X) - train_sample_size:, ].T\n",
    "Y_train = Y[0][:len(X) - train_sample_size]\n",
    "Y_dev = Y[0][len(X) - train_sample_size:]\n",
    "\n",
    "\n",
    "Y_train = convert_to_one_hot(Y_train, 2)\n",
    "Y_dev = convert_to_one_hot(Y_dev, 2)\n",
    "\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(1)\n",
    "def initialize_network():\n",
    "    W1 = tf.get_variable(\"W1\", [4,7], initializer = tf.contrib.layers.xavier_initializer(seed = 4))\n",
    "    b1 = tf.get_variable(\"b1\", [4,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [7,4], initializer = tf.contrib.layers.xavier_initializer(seed = 4))\n",
    "    b2 = tf.get_variable(\"b2\", [7,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [4,7], initializer = tf.contrib.layers.xavier_initializer(seed = 4))\n",
    "    b3 = tf.get_variable(\"b3\", [4,1], initializer = tf.zeros_initializer())\n",
    "    W4 = tf.get_variable(\"W4\", [2,4], initializer = tf.contrib.layers.xavier_initializer(seed = 4))\n",
    "    b4 = tf.get_variable(\"b4\", [2,1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    parameters = {\n",
    "        \"W1\": W1,\n",
    "        \"b1\": b1,\n",
    "        \"W2\": W2,\n",
    "        \"b2\": b2,\n",
    "        \"W3\": W3,\n",
    "        \"b3\": b3,\n",
    "        \"W4\": W4,\n",
    "        \"b4\": b4\n",
    "    }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, dropout = 0.8):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    W3 = parameters[\"W3\"]\n",
    "    b3 = parameters[\"b3\"]\n",
    "    W4 = parameters[\"W4\"]\n",
    "    b4 = parameters[\"b4\"]\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1,X), b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    Z4 = tf.add(tf.matmul(W4, A3), b4)\n",
    "    return Z4\n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = labels))\n",
    "    return cost\n",
    "\n",
    "def compute_cost_l2_reg(Z3, Y, parameters, beta=0.01):\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    L = len(parameters) // 2\n",
    "    reg = 0\n",
    "    for l in range(1, L):\n",
    "        reg += tf.nn.l2_loss(parameters[\"W\" + str(l)])\n",
    "    cost = tf.reduce_mean(cost + reg * beta) \n",
    "    \n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_dev, Y_dev, X_test, dropout=0.8, learning_rate = 0.005, num_iterations = 10000, print_cost = True):\n",
    "    tf.reset_default_graph()\n",
    "    X, Y = create_placeholders(7,2)\n",
    "    parameters = initialize_network()\n",
    "    Z3 = forward_propagation(X, parameters, dropout=dropout)\n",
    "    cost = compute_cost_l2_reg(Z3, Y, parameters)\n",
    "    costs = []\n",
    "    \n",
    "    step = tf.Variable(0, trainable=False)\n",
    "    rate = tf.train.exponential_decay(learning_rate, step, 10000, 0.90)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = rate).minimize(cost, global_step=step)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    init_l = tf.local_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        each_cost = 0\n",
    "        for i in range(num_iterations):\n",
    "            _, each_cost = sess.run([optimizer, cost], feed_dict = {X: X_train, Y:Y_train})\n",
    "            if print_cost and i%5000 == 0:\n",
    "                print(\"Cost at %i is %f\"%(i, each_cost))\n",
    "            if i % 10 == 0:\n",
    "                costs.append(each_cost)\n",
    "        \n",
    "        #Metrics business\n",
    "        output = tf.argmax(Z3)\n",
    "        labels = tf.argmax(Y)\n",
    "        correct_prediction = tf.equal(output, labels)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "       \n",
    "        #training and testing accuracy\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y:Y_train})\n",
    "        dev_accuracy = accuracy.eval({X: X_dev, Y: Y_dev})\n",
    "        #precision and recall\n",
    "        precisions = tf.metrics.precision(labels, output)\n",
    "        recalls = tf.metrics.recall(labels, output)\n",
    "        \n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        precisions = sess.run(precisions, feed_dict={X: X_dev, Y: Y_dev})[1]\n",
    "        recalls = sess.run(recalls, feed_dict={X: X_dev, Y: Y_dev})[1]\n",
    "        f1_score = 2 * precisions * recalls / (precisions + recalls)\n",
    "        \n",
    "        metrics = {\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"dev_accuracy\": dev_accuracy,\n",
    "            \"precision\": precisions,\n",
    "            \"recall\": recalls,\n",
    "            \"f1_score\": f1_score\n",
    "        }\n",
    "        \n",
    "        \n",
    "        return metrics, costs, sess.run(parameters), sess.run(output, feed_dict={X: X_test}).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, costs, parameters, Y_pred = model(X_train, Y_train, X_dev, Y_dev, X_test.T, num_iterations=40000, learning_rate = 0.1, print_cost = False)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(costs)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.ylim(0.35, 0.8)\n",
    "plt.title(\"learning_rate = 0.0005\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "output['PassengerId'] = passengerIds\n",
    "output['Survived'] = Y_pred.astype(int)\n",
    "output.to_csv('./prediction.csv', index=False)\n",
    "print(Y_pred)\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Kaggle Score: 0.79425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
